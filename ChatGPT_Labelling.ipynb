{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT Labelling\n",
    "\n",
    "#### Glossary\n",
    "\n",
    "1. ChatGPT API Connection\n",
    "2. Verification of the labelling on text already labelled by us\n",
    "3. Labelling by ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai\n",
    "#!pip install langchain\n",
    "#!pip install python-Levenshtein\n",
    "#!pip install fuzzywuzzy\n",
    "#!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import pickle\n",
    "import Levenshtein\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from ecbdata import ecbdata\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "\n",
    "from openai import OpenAI\n",
    "from jinja2 import Template\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "#ECB Color\n",
    "color = (17/255, 49/255, 147/255)\n",
    "\n",
    "# File containing the functions\n",
    "from src.Metaphor_Labelling_Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Api Key: \n",
    "api_key = open(\"C:\\\\Users\\\\School\\\\Desktop\\\\GPT_KEY.txt\", \"r\").read()\n",
    "\n",
    "# Target words:\n",
    "words_to_match = [\"inflation\",\"deflation\",\"inflationary\",\"desinflationary\",\"hyperinflation\",\"disinflation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset containing the interveiw data\n",
    "df = pd.read_csv('Data/Final_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media</th>\n",
       "      <th>Member</th>\n",
       "      <th>Link</th>\n",
       "      <th>Information</th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Metaphors</th>\n",
       "      <th>Metaphors Sentence</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_metaphors_len</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Sentences_len</th>\n",
       "      <th>Sentence_GPT_Majority</th>\n",
       "      <th>GPT_Majority_Category</th>\n",
       "      <th>Matched_Metaphors</th>\n",
       "      <th>pos_relationships</th>\n",
       "      <th>pos_sentences</th>\n",
       "      <th>pos_relationships_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2005-12-23</td>\n",
       "      <td>Interview with Der Spiegel</td>\n",
       "      <td>Jean-Claude Trichet</td>\n",
       "      <td>https://www.ecb.europa.eu/press/inter/date/200...</td>\n",
       "      <td>Information not found</td>\n",
       "      <td>SPIEGEL: Monsieur Trichet, any concrete uttera...</td>\n",
       "      <td>The publication of the translation was authori...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>['We will in the future take the decisions tha...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>['we will in the future take the decisions tha...</td>\n",
       "      <td>['machine', 'disease', 'plant']</td>\n",
       "      <td>[True, True, True]</td>\n",
       "      <td>[('inflationary', 'expectation'), ('inflation'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2005-12-19</td>\n",
       "      <td>Interview with Hospodářské Noviny</td>\n",
       "      <td>Otmar Issing</td>\n",
       "      <td>https://www.ecb.europa.eu/press/inter/date/200...</td>\n",
       "      <td>Information not found</td>\n",
       "      <td>The new EU member states want to adopt the eur...</td>\n",
       "      <td>These questions are all closely related to eac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>['We are not confronted with deflation but wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['we are not confronted with deflation but wit...</td>\n",
       "      <td>['warfare']</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2005-12-19</td>\n",
       "      <td>Interview with Financial Times and Financial T...</td>\n",
       "      <td>Lucas Papademos</td>\n",
       "      <td>https://www.ecb.europa.eu/press/inter/date/200...</td>\n",
       "      <td>Information not found</td>\n",
       "      <td>Mr Papademos, you have responsibility as ECB V...</td>\n",
       "      <td>A comparison of the risks involved when short-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>['If longterm interest rates remain at a low l...</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>['in the us the policy stance changed and the ...</td>\n",
       "      <td>['fire', 'fire', 'fire', 'fire']</td>\n",
       "      <td>[True, True, True, True]</td>\n",
       "      <td>[('future', 'inflation'), ('low', 'inflation')...</td>\n",
       "      <td>['it a higher level of interest rates could fo...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2005-12-15</td>\n",
       "      <td>Interview with Paris Match</td>\n",
       "      <td>Jean-Claude Trichet</td>\n",
       "      <td>https://www.ecb.europa.eu/press/inter/date/200...</td>\n",
       "      <td>Information not found</td>\n",
       "      <td>Paris Match. After two uneventful years at the...</td>\n",
       "      <td>The publication of the translation was authori...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>['You are exaggerating the increase in the cos...</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>['furthermore we must not wait until inflation...</td>\n",
       "      <td>['warfare', 'disease', 'disease', 'machine', '...</td>\n",
       "      <td>[True, True, True, True, True]</td>\n",
       "      <td>[('inflationary', 'remain'), ('inflationary', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-09</td>\n",
       "      <td>Interview in Il Giornale</td>\n",
       "      <td>Lorenzo Bini Smaghi</td>\n",
       "      <td>https://www.ecb.europa.eu/press/inter/date/200...</td>\n",
       "      <td>Information not found</td>\n",
       "      <td>However, Europe’s politicians, with few except...</td>\n",
       "      <td>By Angelo Allegri, our correspondent in Frankf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>['The rise has helped to keep inflation expect...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>['the rise has helped to keep inflation expect...</td>\n",
       "      <td>['orientation', 'orientation', 'orientation', ...</td>\n",
       "      <td>[True, True, True, True, True, True, True]</td>\n",
       "      <td>[('inflation', 'regard')]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date                                              Media  \\\n",
       "0           0  2005-12-23                         Interview with Der Spiegel   \n",
       "1           1  2005-12-19                  Interview with Hospodářské Noviny   \n",
       "2           2  2005-12-19  Interview with Financial Times and Financial T...   \n",
       "3           3  2005-12-15                         Interview with Paris Match   \n",
       "4           4  2005-12-09                           Interview in Il Giornale   \n",
       "\n",
       "                Member                                               Link  \\\n",
       "0  Jean-Claude Trichet  https://www.ecb.europa.eu/press/inter/date/200...   \n",
       "1         Otmar Issing  https://www.ecb.europa.eu/press/inter/date/200...   \n",
       "2      Lucas Papademos  https://www.ecb.europa.eu/press/inter/date/200...   \n",
       "3  Jean-Claude Trichet  https://www.ecb.europa.eu/press/inter/date/200...   \n",
       "4  Lorenzo Bini Smaghi  https://www.ecb.europa.eu/press/inter/date/200...   \n",
       "\n",
       "             Information                                          Questions  \\\n",
       "0  Information not found  SPIEGEL: Monsieur Trichet, any concrete uttera...   \n",
       "1  Information not found  The new EU member states want to adopt the eur...   \n",
       "2  Information not found  Mr Papademos, you have responsibility as ECB V...   \n",
       "3  Information not found  Paris Match. After two uneventful years at the...   \n",
       "4  Information not found  However, Europe’s politicians, with few except...   \n",
       "\n",
       "                                             Answers Metaphors  \\\n",
       "0  The publication of the translation was authori...       NaN   \n",
       "1  These questions are all closely related to eac...       NaN   \n",
       "2  A comparison of the risks involved when short-...       NaN   \n",
       "3  The publication of the translation was authori...       NaN   \n",
       "4  By Angelo Allegri, our correspondent in Frankf...       NaN   \n",
       "\n",
       "  Metaphors Sentence  ...  pos_metaphors_len  \\\n",
       "0                NaN  ...                  0   \n",
       "1                NaN  ...                  0   \n",
       "2                NaN  ...                  2   \n",
       "3                NaN  ...                  0   \n",
       "4                NaN  ...                  0   \n",
       "\n",
       "                                           Sentences Frequency Sentences_len  \\\n",
       "0  ['We will in the future take the decisions tha...         5             3   \n",
       "1  ['We are not confronted with deflation but wit...         1             1   \n",
       "2  ['If longterm interest rates remain at a low l...        18            11   \n",
       "3  ['You are exaggerating the increase in the cos...         7             5   \n",
       "4  ['The rise has helped to keep inflation expect...         7             7   \n",
       "\n",
       "                               Sentence_GPT_Majority  \\\n",
       "0  ['we will in the future take the decisions tha...   \n",
       "1  ['we are not confronted with deflation but wit...   \n",
       "2  ['in the us the policy stance changed and the ...   \n",
       "3  ['furthermore we must not wait until inflation...   \n",
       "4  ['the rise has helped to keep inflation expect...   \n",
       "\n",
       "                               GPT_Majority_Category  \\\n",
       "0                    ['machine', 'disease', 'plant']   \n",
       "1                                        ['warfare']   \n",
       "2                   ['fire', 'fire', 'fire', 'fire']   \n",
       "3  ['warfare', 'disease', 'disease', 'machine', '...   \n",
       "4  ['orientation', 'orientation', 'orientation', ...   \n",
       "\n",
       "                            Matched_Metaphors  \\\n",
       "0                          [True, True, True]   \n",
       "1                                      [True]   \n",
       "2                    [True, True, True, True]   \n",
       "3              [True, True, True, True, True]   \n",
       "4  [True, True, True, True, True, True, True]   \n",
       "\n",
       "                                   pos_relationships  \\\n",
       "0  [('inflationary', 'expectation'), ('inflation'...   \n",
       "1                                                 []   \n",
       "2  [('future', 'inflation'), ('low', 'inflation')...   \n",
       "3  [('inflationary', 'remain'), ('inflationary', ...   \n",
       "4                          [('inflation', 'regard')]   \n",
       "\n",
       "                                       pos_sentences pos_relationships_len  \n",
       "0                                                 []                     3  \n",
       "1                                                 []                     0  \n",
       "2  ['it a higher level of interest rates could fo...                     8  \n",
       "3                                                 []                     2  \n",
       "4                                                 []                     1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                               62\n",
       "Date                                                             2010-05-21\n",
       "Media                     Interview with Frankfurter Allgemeine Zeitung ...\n",
       "Member                                                  Jean-Claude Trichet\n",
       "Link                      https://www.ecb.europa.eu/press/inter/date/201...\n",
       "Information                                           Information not found\n",
       "Questions                 FAZ:[end_question] Trichet:[end_question] FAZ:...\n",
       "Answers                   Trichet: We are constantly urging the banks to...\n",
       "Metaphors                                                               NaN\n",
       "Metaphors Sentence                                                      NaN\n",
       "YoB                                                                    1942\n",
       "Gender                                                                    M\n",
       "Country                                                              France\n",
       "Period on the Board                                             2003 - 2011\n",
       "list_regex                                                               []\n",
       "list_regex_reduced                                                       []\n",
       "list_regex_len                                                            0\n",
       "list_regex_reduced_len                                                    0\n",
       "text_length                                                             693\n",
       "pos_metaphors                                                            []\n",
       "pos_metaphors_len                                                         0\n",
       "Sentences                                                                []\n",
       "Frequency                                                                 0\n",
       "Sentences_len                                                             0\n",
       "Sentence_GPT_Majority                                                    []\n",
       "GPT_Majority_Category                                                    []\n",
       "Matched_Metaphors                                                        []\n",
       "pos_relationships                                                        []\n",
       "pos_sentences                                                            []\n",
       "pos_relationships_len                                                     0\n",
       "Name: 62, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[62]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Prepare the data for the labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 519/519 [00:00<00:00, 32528.56it/s]\n",
      "100%|██████████| 519/519 [00:00<00:00, 2973.66it/s]\n",
      "100%|██████████| 519/519 [00:00<00:00, 2177.05it/s]\n",
      "100%|██████████| 519/519 [00:00<00:00, 520651.47it/s]\n",
      "100%|██████████| 519/519 [00:00<00:00, 1634.85it/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(df,words_to_match):\n",
    "        text_preproc = (\n",
    "                df.Answers\n",
    "                .astype(str)\n",
    "                .progress_apply(lambda row: remove_end_answer(row))\n",
    "                .progress_apply(lambda row: remove_special_characters_keep_point(row))\n",
    "                .progress_apply(lambda row: remove_unnecessary_spaces(row))\n",
    "                .progress_apply(lambda row: remove_starting_month(row))\n",
    "                .progress_apply(lambda row: extract_sentences(row,words_to_match)))\n",
    "\n",
    "        df[\"Sentences\"]=text_preproc\n",
    "\n",
    "        return df\n",
    "\n",
    "df = preprocess_text(df, words_to_match=words_to_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Frequency\"] = df[\"Answers\"].apply(count_frequency, words_to_match=words_to_match)\n",
    "df['Sentences_len'] = df['Sentences'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of Frequency and Sentences_len\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "sns.histplot(df[\"Frequency\"], ax=ax[0], color=color)\n",
    "ax[0].set_title(\"Frequency distribution\")\n",
    "sns.histplot(df[\"Sentences_len\"], ax=ax[1], color=color)\n",
    "ax[1].set_title(\"Sentences length distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeled Data\n",
    "\n",
    "We will use the human labeled data to verify the perfromance of Chat GPT 4o to extract, identify and classify conceptual metaphors. \n",
    "\n",
    "If the perfromance of Chat GPT is considered as equal to human perfromance, then we will use GPT to label the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the labeled data: (68, 56)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Dataframe with the labeled Metaphors\n",
    "df_labels = df[df['Metaphors'].notnull()].copy()\n",
    "print(\"Shape of the dataset with labeled Metaphors: \", df_labels.shape)\"\"\"\n",
    "\n",
    "df_labels = pd.read_csv('Data/Labeled_Data.csv')\n",
    "print(\"Shape of the labeled data:\", df_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell could be unnecessay in later versions (or only run ones!)\n",
    "\n",
    "# lambda function to convert string representations of lists into actual lists\n",
    "parse_list = lambda x: ast.literal_eval(x) if x != '[\\'None\\']' else []\n",
    "df_labels.loc[:, 'Metaphors Sentence'] = df_labels['Metaphors Sentence'].apply(parse_list)\n",
    "df_labels.loc[:, 'Sentences'] = df_labels['Sentences'].apply(parse_list)\n",
    "df_labels.loc[:, 'Category_Labeled'] = df_labels['Category_Labeled'].apply(parse_list)\n",
    "\n",
    "# lambda function to count the elements in each list\n",
    "df_labels.loc[:, 'Metaphors_len'] = df_labels['Metaphors Sentence'].apply(len)\n",
    "df_labels.loc[:, 'Sentences_len'] = df_labels['Sentences'].apply(len)\n",
    "df_labels.loc[:, 'Category_len'] = df_labels['Category_Labeled'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Metaphors (Label):  493\n",
      "Total number of Sentences (with words_to_match):  577\n",
      "Average number of Metaphors per Interview:  7.25\n",
      "Ratio of Metaphors to Sentences:  0.854419410745234\n"
     ]
    }
   ],
   "source": [
    "# Print total number of Metaphors\n",
    "print(\"Total number of Metaphors (Label): \", df_labels['Metaphors_len'].sum())\n",
    "print(\"Total number of Sentences (with words_to_match): \", df_labels['Sentences'].apply(len).sum())\n",
    "print(\"Average number of Metaphors per Interview: \", df_labels['Metaphors_len'].mean())\n",
    "print(\"Ratio of Metaphors to Sentences: \", df_labels['Metaphors_len'].sum() / df_labels['Sentences'].apply(len).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the labeled Metaphors have the Starting date of the interview, we need to remove it as it was removed from the Sentences\n",
    "df_labels['Metaphors Sentence'] = df_labels['Metaphors Sentence'].apply(lambda x: [remove_starting_month(sentence) for sentence in x])\n",
    "\n",
    "# Some of the labeled Metaphors have a \"low;\" in the string resulting from an error, we need to remove it as it not present in the Sentences\n",
    "df_labels['Metaphors Sentence'] = df_labels['Metaphors Sentence'].apply(lambda x: [sentence.replace(\"low;\", \" \") for sentence in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475, 493)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check: Match 'Metaphors Sentence' with 'Sentences' to see if they are present\n",
    "df_temp = add_match_column(df_labels.copy(), threshold=0.5)\n",
    "\n",
    "# Compare the 'Matched_Labeled_len' with 'Metaphors_len' to see if all the Metaphors are matched\n",
    "df_temp['Matched_Labeled_len'].sum(), df_temp['Metaphors_len'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the labeled sentences do not match with the 'Sentences' extracted from the interviews. The Fuzzy threshold had to be set to 0.5 to match the most possible Metaphors. This might be due to Human error while labeling or the preprocessing step removing special characters such as \"-\" that might change the meaning of a word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ChatGPT API Connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_prompt = open(\"GPT_Prompts/Prompt_1.txt\", \"r\").read()\n",
    "\n",
    "following_prompts = \"\"\"Detect and extract the conceptual metaphors related to inflation, deflation, inflationary, disinflationary, hyperinflation, and disinflation in the following sentences:\n",
    "{{list_sentences}}\n",
    "\n",
    "Return the metaphors in the format:\n",
    "Sentence: [Sentence text] Category: [Category]\n",
    "\n",
    "Where, Category is one of the following:\n",
    "Fire, Liquids, Plant, Animal, Disease, Warfare, Sports, Machine, Orientation, Other\n",
    "\n",
    "The output has to be in the right format. The categories are predefined and you have to choose the right category based on the metaphor used in the sentence.\n",
    "\"\"\"\n",
    "\n",
    "following_prompts = Template(following_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On the other hand in July there were upside risks to inflation but now they are balanced.',\n",
       " 'This is a major asset for Europe it protects us from the materialisation of the risk of inflation as well as the materialisation of the risk of deflation.']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels[\"Sentences\"].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect and extract the conceptual metaphors related to inflation, deflation, inflationary, disinflationary, hyperinflation, and disinflation in the following sentences:\n",
      "['If longterm interest rates remain at a low level as a result of favourable inflation expectations influenced by a credible monetary policy oriented towards price stability and as a consequence of the impact of other factors then the effect on economic activity of a rise in shortterm interest rates is going to be more muted.', 'Public perceptions and expectations of future inflation should be favourably influenced by a change in the monetary policy stance that aims at preserving price stability.', 'It a higher level of interest rates could foster expectations of lower inflation and higher real disposable incomes and increase confidence particularly in countries where public perceptions of current inflation are less favourable than actual inflation and financial markets inflation expectations.', 'It was necessary in order to preserve price stability over the medium term in view of several upside risks to price stability that had been identified and in order to send a clear signal that the ECB is determined to continue pursuing a credible policy that will preserve price stability over the medium term and continue to anchor inflation expectations to price stability.', 'It was also prudent to decide on a moderate change in the stance taking into account the uncertainty surrounding the evolution and effects of other determinants of inflation dynamics.', 'In the US the policy stance changed and the decision to preannounce a measured increase in interest rates was made at a time when interest rates were at the very low level of 1 per cent and had stayed at that level for a considerable period and also at a time when it was assessed that inflationary pressures were building up on both the demand and the supply sides of the American economy.', 'Second our assessment about the outlook for price stability is that inflation is expected to stay above 2 per cent for a period of time but it is expected to moderate gradually.', 'In the absence of secondround effects the relatively modest increase in unit labour costs partly related to the fact that the pace of the recovery is moderate and there is still an output gap and a high rate of unemployment is expected to help contain inflationary pressures.', 'They are useful benchmarks not intermediate objectives that can be used together with other measures such as the output gap and the difference between the unemployment rate and what could be labelled the natural rate of unemployment to provide information about the strength of inflationary pressures in the economy.', 'Recent research at the ECB and by academic economists and international institutions suggests that the natural rate of unemployment or the NAIRU nonaccelerating inflation rate of unemployment is currently close to 8 per cent.', 'If the NAIRU is reduced a higher level of employment and a lower rate of unemployment can be supported by monetary policy without creating inflationary pressures.']\n",
      "\n",
      "Return the metaphors in the format:\n",
      "Sentence: [Sentence text] Category: [Category]\n",
      "\n",
      "Where, Category is one of the following:\n",
      "Fire, Liquids, Plant, Animal, Disease, Warfare, Sports, Machine, Orientation, Other\n",
      "\n",
      "The output has to be in the right format. The categories are predefined and you have to choose the right category based on the metaphor used in the sentence.\n",
      "405\n"
     ]
    }
   ],
   "source": [
    "print(following_prompts.render(list_sentences=df[\"Sentences\"].iloc[2]))\n",
    "\n",
    "# Limit size of df to 10\n",
    "#df_labels = df_labels.iloc[:10]\n",
    "\n",
    "sentences_list = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sentences = row[\"Sentences\"]\n",
    "    if len(sentences) > 0:\n",
    "        sentences_list.append(sentences)\n",
    "\n",
    "print(len(sentences_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title: Conceptual Metaphor Detection\\n\\nDescription: Detect and extract conceptual Metaphors in a set of sentences.\\n\\nTask: Given a set of sentences, you are required to identify and extract conceptual metaphors present.  \\nOnly consider conceptual metaphors related to inflation, deflation, inflationary, disinflationary, hyperinflation, and disinflation.\\nAfter identifying the metaphors, return the sentences that contain the metaphors and label it in the format:\\n\\nSentence: [Sentence text] Category: [Category]\\n\\nWhere, Category is one of the following 10 options (with a set of examples):\\nFire = [\\'ignite\\', \\'fuel\\', \\'spark\\', \\'dampen\\', \\'stoke\\', \\'kindle\\', \\'choke\\', \\'stifle\\', \\'fan\\', \\'flare-up\\', \\'douse\\', \\'snuff\\']\\nLiquids = [\\'erode\\', \\'surge\\', \\'subside\\', \\'simmers\\', \\'emergence\\', \\'ebb\\', \\'dilute\\', \\'spurt\\', \\'recede\\', \\'buoy\\']\\nPlant = [\\'hedge\\', \\'nip\\']\\nAnimal = [\\'soar\\', \\'rampant\\', \\'curb\\', \\'tame\\', \\'rein\\', \\'creep\\', \\'whip\\', \\'gallop\\', \\'halt\\', \\'roar\\', \\'curtail\\', \\'gnaw\\', \\'hibernation\\',\\'Pounce\\',\\'Stalk\\',\\'Bite\\',\\'Claw\\',\\'Snarl\\',\\'Charge\\',\\'Hunt\\',\\'Intimidate\\',\\'Defend\\',\\'Rend\\',\\'Tear\\',\\'Dominated\\',\\'Fangs\\',\\'Claws\\',\\'Predation\\',\\'Territoriality\\',\\'Hackles\\',\\'Prowess\\',\\'Strength\\',\\'Ferocity\\',\\'Dominance\\',\\'Menace\\',\\'Threat\\',\\'piercing\\',\\'glaring\\',\\'Talons\\',\\'Paws\\',\\'Horns\\',\\'Tusks\\',\\'Fierce\\',\\'Savage\\',\\'Ruthless\\',\\'Daunting\\',\\'Wild\\',\\'Untamed\\',\\'Ferocious\\',\\'prey\\']\\nDisease = [\\'plague\\', \\'worsen\\', \\'benign\\', \\'virulent\\', \\'debilitate\\', \\'bout\\', \\'chronically\\']\\nWarfare = [\\'threat\\', \\'subdue\\', \\'target\\', \\'beat\\', \\'preempt\\', \\'vigilant\\', \\'ravage\\', \\'undermine\\', \\'forestall\\', \\'counteract\\', \\'eliminate\\', \\'ferocious\\', \\'ruinous\\', \\'clobber\\', \\'buster\\', \\'eradicate\\', \\'besieged\\', \\'thwart\\', \\'bash\\', \\'beset\\']\\nSports = [\\'pace\\', \\'outstrip\\', \\'lag\\', \\'surpass\\', \\'quicken\\', \\'outrun\\', \\'bout\\', \\'best\\', \\'tug-of-war\\', \\'zip\\', \\'overtake\\']\\nMachine = [\\'accelerate\\', \\'faster\\', \\'control\\', \\'slow\\', \\'trigger\\', \\'skyrocket\\', \\'rapid\\', \\'heat\\', \\'escalate\\', \\'decelerate\\', \\'ratchet\\', \\'unchecked\\', \\'readjusted\\', \\'chug\\', \\'damper\\', \\'zoom\\']\\nOrientation = [\\'low\\', \\'rise\\', \\'high\\', \\'increase\\', \\'reduce\\', \\'decline\\', \\'fall\\', \\'exceed\\', \\'spiral\\', \\'hyper\\', \\'upward\\', \\'uptick\\', \\'downward\\', \\'boost\\', \\'peak\\', \\'diminish\\', \\'upturn\\', \\'hike\\', \\'plummet\\', \\'upswing\\']\\nOther = [any other metaphor not covered by the above categories]\\n\\nDefinition: Conceptual metaphors refer to linguistic expressions that metaphorically represent abstract concepts in terms of more concrete concepts.\\n\\nIdentifying Metaphorical and Non-Metaphorical Usage:\\nTo identify whether the use of \"inflation\" is metaphorical or non-metaphorical, consider the following questions:\\n\\nIs another domain being used to describe inflation?: Check if the sentence draws on concepts from a different area of experience to explain or depict inflation.\\nMetaphorical: \"Inflation is eroding our savings.\" (Here, \"eroding\" draws on the domain of natural wear and tear, often associated with physical erosion.)\\nNon-Metaphorical: \"Inflation is measured by the Consumer Price Index.\" (This is a straightforward, literal description.)\\n\\nIs the language used more concrete and vivid?: Metaphors often use vivid and concrete imagery to make abstract ideas more relatable.\\nMetaphorical: \"Inflation is a beast that must be tamed.\" (The use of \"beast\" provides a vivid and concrete image.)\\nNon-Metaphorical: \"Inflation affects the purchasing power of money.\" (This is a direct explanation without vivid imagery.)\\n\\nIs the purpose to simplify and relate?: Metaphors are often used to simplify complex ideas and relate them to common experiences.\\nMetaphorical: \"The economy is overheating due to inflation.\" (This uses the concept of overheating, which is a familiar experience, to explain economic stress.)\\nNon-Metaphorical: \"High inflation rates can lead to increased interest rates.\" (This is a factual statement explaining a cause-and-effect relationship.)\\n\\nAdditional Instructions:\\n- If one sentence contains multiple metaphors, return the sentence multiple times with each metaphor labeled separately.\\n\\nExample Input:\\n[\"China worries that such rapid growth could ignite inflation, and the countrys banking industry has been trying since last year to bring the rate down to 7 percent a year.\",\\n\"But the evidence from that earlier period is tainted by the fact that inflation was roaring at the time creating bracket creep, over-taxation of illusory capital gains and paper profits, and rising interest rates.\"]\\n\\nExample Output:\\n\"Sentence: China worries that such rapid growth could ignite inflation, and the countrys banking industry has been trying since last year to bring the rate down to 7 percent a year. Category: Fire\", \\n\"Sentence: \"But the evidence from that earlier period is tainted by the fact that inflation was roaring at the time creating bracket creep, over-taxation of illusory capital gains and paper profits, and rising interest rates.\" Category: Animal\"\\n\\nThe output has to be in the right format as shown in the example output. The categories are predefined and you have to choose the right category based on the metaphor used in the sentence.',\n",
       " \"Detect and extract the conceptual metaphors related to inflation, deflation, inflationary, disinflationary, hyperinflation, and disinflation in the following sentences:\\n['We will in the future take the decisions that will be necessary to deliver price stability to be credible in delivering price stability over time and to preserve the solid anchoring of inflationary expectations at levels consistent with price stability.', 'This is a risk which in turn would affect inflation permanently in the future.', 'Our decision by stabilising inflationary expectations preserves a financial environment which is favourable to sustainable growth and job creation.']\\n\\nReturn the metaphors in the format:\\nSentence: [Sentence text] Category: [Category]\\n\\nWhere, Category is one of the following:\\nFire, Liquids, Plant, Animal, Disease, Warfare, Sports, Machine, Orientation, Other\\n\\nThe output has to be in the right format. The categories are predefined and you have to choose the right category based on the metaphor used in the sentence.\",\n",
       " \"Detect and extract the conceptual metaphors related to inflation, deflation, inflationary, disinflationary, hyperinflation, and disinflation in the following sentences:\\n['We are not confronted with deflation but with increased risks to price stability this in the reason why we raised our interest rates.']\\n\\nReturn the metaphors in the format:\\nSentence: [Sentence text] Category: [Category]\\n\\nWhere, Category is one of the following:\\nFire, Liquids, Plant, Animal, Disease, Warfare, Sports, Machine, Orientation, Other\\n\\nThe output has to be in the right format. The categories are predefined and you have to choose the right category based on the metaphor used in the sentence.\"]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_prompts = [initial_prompt] + [following_prompts.render(list_sentences=sentences) for sentences in sentences_list]\n",
    "all_prompts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prompts = [[{\"role\": \"system\", \"content\": prompt}] for prompt in all_prompts]\n",
    "#all_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'client = OpenAI(api_key=api_key)\\n\\n# model: \"gpt-3.5-turbo\", \"gpt-4o\"\\n# temperature: Controls the creativity of the responses. Lower values make the output more focused and deterministic, while higher values make it more random\\n# We want GPT to be more deterministic and focused, and return the metaphors in the right format - Default value: 0\\ngpt_answer = [client.chat.completions.create(messages=msg, model=\\'gpt-4o\\', temperature=0).choices[0].message.content for msg in all_prompts]'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"client = OpenAI(api_key=api_key)\n",
    "\n",
    "# model: \"gpt-3.5-turbo\", \"gpt-4o\"\n",
    "# temperature: Controls the creativity of the responses. Lower values make the output more focused and deterministic, while higher values make it more random\n",
    "# We want GPT to be more deterministic and focused, and return the metaphors in the right format - Default value: 0\n",
    "gpt_answer = [client.chat.completions.create(messages=msg, model='gpt-4o', temperature=0).choices[0].message.content for msg in all_prompts]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt_answer\\nprint(len(gpt_answer))'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"gpt_answer\n",
    "print(len(gpt_answer))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Save the GPT-4 output to a pickle file\\nwith open('gpt_answer_all_3.pkl', 'wb') as f:\\n    pickle.dump(gpt_answer, f)\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Save the GPT-4 output to a pickle file\n",
    "with open('gpt_answer_all_3.pkl', 'wb') as f:\n",
    "    pickle.dump(gpt_answer, f)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the 3 different outputs:\n",
    "\n",
    "As 3 different prompts were tested and saved, now we will analyse the outputs and keep the metaphors appearing at least twice in a final 'robust' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the GPT-4 output for the first prompt:  58\n",
      "The length of the GPT-4 output for the second prompt:  58\n",
      "The length of the GPT-4 output for the third prompt:  58\n"
     ]
    }
   ],
   "source": [
    "# Load the GPT-4 output from the pickle file\n",
    "with open('GPT_Output/gpt_answer_1.pkl', 'rb') as f:\n",
    "    gpt_answer_1 = pickle.load(f)\n",
    "\n",
    "with open('GPT_Output/gpt_answer_2.pkl', 'rb') as f:\n",
    "    gpt_answer_2 = pickle.load(f)\n",
    "\n",
    "with open('GPT_Output/gpt_answer_3.pkl', 'rb') as f:\n",
    "    gpt_answer_3 = pickle.load(f)\n",
    "\n",
    "# Drop the first element which is the initial prompt\n",
    "gpt_answer_1 = gpt_answer_1[1:]\n",
    "gpt_answer_2 = gpt_answer_2[1:]\n",
    "gpt_answer_3 = gpt_answer_3[1:]\n",
    "\n",
    "gpt_names = [\"GPT_1\", \"GPT_2\", \"GPT_3\", \"GPT_Majority\"]\n",
    "\n",
    "print(\"The length of the GPT-4 output for the first prompt: \", len(gpt_answer_1))\n",
    "print(\"The length of the GPT-4 output for the second prompt: \", len(gpt_answer_2))\n",
    "print(\"The length of the GPT-4 output for the third prompt: \", len(gpt_answer_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset before adding GPT-4 output:  (68, 56)\n",
      "Shape of the dataset after dropping empty Sentences:  (68, 56)\n",
      "Shape of the dataset after adding GPT-4 output:  (68, 56)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the dataset before adding GPT-4 output: \", df_labels.shape)\n",
    "\n",
    "# Drop the rows where the Sentences are empty\n",
    "#df_labels = df_labels[df_labels['Sentences'].apply(len) > 0]\n",
    "\n",
    "print(\"Shape of the dataset after dropping empty Sentences: \", df_labels.shape)\n",
    "\n",
    "for gpt_name, gpt_answer in zip(gpt_names, [gpt_answer_1, gpt_answer_2, gpt_answer_3]):\n",
    "    df_labels = add_columns_to_dataframe(df_labels, gpt_answer, name=gpt_name)\n",
    "\n",
    "print(\"Shape of the dataset after adding GPT-4 output: \", df_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Metaphors labeled:  493\n",
      "Total number of Sentences (with words_to_match):  577\n",
      "\n",
      "Total number of sentences in the 'Sentence_GPT_1' column:  497\n",
      "Total number of sentences in the 'Sentence_GPT_2' column:  497\n",
      "Total number of sentences in the 'Sentence_GPT_3' column:  505\n",
      "\n",
      "Ratio of GPT (Prompt 1) Metaphors to Sentences:  0.8613518197573656\n",
      "Ratio of GPT (Prompt 2) Metaphors to Sentences:  0.8613518197573656\n",
      "Ratio of GPT (Prompt 3) Metaphors to Sentences:  0.8752166377816292\n"
     ]
    }
   ],
   "source": [
    "# Sanity check:\n",
    "print(\"Total number of Metaphors labeled: \", df_labels['Metaphors_len'].sum())\n",
    "print(\"Total number of Sentences (with words_to_match): \", df_labels['Sentences'].apply(len).sum())\n",
    "print(\"\")\n",
    "print(\"Total number of sentences in the 'Sentence_GPT_1' column: \", df_labels['Sentence_GPT_1'].apply(len).sum())\n",
    "print(\"Total number of sentences in the 'Sentence_GPT_2' column: \", df_labels['Sentence_GPT_2'].apply(len).sum())\n",
    "print(\"Total number of sentences in the 'Sentence_GPT_3' column: \", df_labels['Sentence_GPT_3'].apply(len).sum())\n",
    "print(\"\")\n",
    "print(\"Ratio of GPT (Prompt 1) Metaphors to Sentences: \", df_labels['Sentence_GPT_1'].apply(len).sum() / df_labels['Sentences'].apply(len).sum())\n",
    "print(\"Ratio of GPT (Prompt 2) Metaphors to Sentences: \", df_labels['Sentence_GPT_2'].apply(len).sum() / df_labels['Sentences'].apply(len).sum())\n",
    "print(\"Ratio of GPT (Prompt 3) Metaphors to Sentences: \", df_labels['Sentence_GPT_3'].apply(len).sum() / df_labels['Sentences'].apply(len).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority voting:\n",
    "\n",
    "Keep only the Metaphors that appear in at least two of the 3 outputs given by 3 different prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of GPT (Majority Vote) Metaphors to Sentences:  0.8769497400346621\n"
     ]
    }
   ],
   "source": [
    "df_labels = majority_voting_with_category(df_labels)\n",
    "print(\"Ratio of GPT (Majority Vote) Metaphors to Sentences: \", df_labels['Sentence_GPT_Majority'].apply(len).sum() / df_labels['Sentences'].apply(len).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio of metaphor per sentence containing the word 'inflation' went up after majority voting, hence resulting in more robust results for the rest of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the labeled sentences and GPT answers to perform analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpt_name in gpt_names:\n",
    "    df_labels = add_comparison_column(df_labels, threshold=30, name=gpt_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaphor matching using Levenstein distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Metaphors (prompt GPT_1):  497\n",
      "Total number of True values for (prompt GPT_1):  383\n",
      "Ratio of Metaphors correctly identified (vs labeled data) (prompt GPT_1):  0.7706237424547284\n",
      "Ratio of Categories correctly identified (vs labeled data) (prompt GPT_1):  0.8048289738430584\n",
      "\n",
      "Total number of Metaphors (prompt GPT_2):  497\n",
      "Total number of True values for (prompt GPT_2):  389\n",
      "Ratio of Metaphors correctly identified (vs labeled data) (prompt GPT_2):  0.7826961770623743\n",
      "Ratio of Categories correctly identified (vs labeled data) (prompt GPT_2):  0.7806841046277666\n",
      "\n",
      "Total number of Metaphors (prompt GPT_3):  505\n",
      "Total number of True values for (prompt GPT_3):  386\n",
      "Ratio of Metaphors correctly identified (vs labeled data) (prompt GPT_3):  0.7643564356435644\n",
      "Ratio of Categories correctly identified (vs labeled data) (prompt GPT_3):  0.7782178217821782\n",
      "\n",
      "Total number of Metaphors (prompt GPT_Majority):  506\n",
      "Total number of True values for (prompt GPT_Majority):  389\n",
      "Ratio of Metaphors correctly identified (vs labeled data) (prompt GPT_Majority):  0.7687747035573123\n",
      "Ratio of Categories correctly identified (vs labeled data) (prompt GPT_Majority):  0.8003952569169961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gpt_name in gpt_names:\n",
    "    print(f\"Total number of Metaphors (prompt {gpt_name}): \", df_labels[f'Sentence_{gpt_name}'].apply(len).sum())\n",
    "    print(f\"Total number of True values for (prompt {gpt_name}): \", df_labels[f'Comparison_Result_{gpt_name}'].apply(sum).sum())\n",
    "    print(f\"Ratio of Metaphors correctly identified (vs labeled data) (prompt {gpt_name}): \", df_labels[f'Comparison_Result_{gpt_name}'].apply(sum).sum() / df_labels[f'Comparison_Result_{gpt_name}'].apply(len).sum())\n",
    "    print(f\"Ratio of Categories correctly identified (vs labeled data) (prompt {gpt_name}): \", df_labels[f'Category_Result_{gpt_name}'].apply(sum).sum() / df_labels[f'Category_Result_{gpt_name}'].apply(len).sum())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Metaphors: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_list = extract_sentences_column(df_labels)\n",
    "metaphors_list = extract_metaphors(df_labels)\n",
    "\n",
    "# Get the true Y values (sentences matching with metaphors labeled)\n",
    "df_true = metrics_dataframe(sentences_list, metaphors_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (prompt GPT_1): 0.7706237424547284\n",
      "Precision (prompt GPT_1): 0.7706237424547284\n",
      "Recall (prompt GPT_1): 0.7768762677484787\n",
      "F1 Score (prompt GPT_1): 0.7737373737373737\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 31  93]\n",
      " [ 52 401]]\n",
      "True Positives (TP): 401\n",
      "True Negatives (TN): 31\n",
      "False Positives (FP): 93\n",
      "False Negatives (FN): 52\n",
      "\n",
      "Accuracy (prompt GPT_2): 0.7826961770623743\n",
      "Precision (prompt GPT_2): 0.7826961770623743\n",
      "Recall (prompt GPT_2): 0.7890466531440162\n",
      "F1 Score (prompt GPT_2): 0.7858585858585859\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 34  90]\n",
      " [ 49 404]]\n",
      "True Positives (TP): 404\n",
      "True Negatives (TN): 34\n",
      "False Positives (FP): 90\n",
      "False Negatives (FN): 49\n",
      "\n",
      "Accuracy (prompt GPT_3): 0.7643564356435644\n",
      "Precision (prompt GPT_3): 0.7643564356435644\n",
      "Recall (prompt GPT_3): 0.7829614604462475\n",
      "F1 Score (prompt GPT_3): 0.7735470941883769\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 26  98]\n",
      " [ 49 404]]\n",
      "True Positives (TP): 404\n",
      "True Negatives (TN): 26\n",
      "False Positives (FP): 98\n",
      "False Negatives (FN): 49\n",
      "\n",
      "Accuracy (prompt GPT_Majority): 0.7687747035573123\n",
      "Precision (prompt GPT_Majority): 0.7687747035573123\n",
      "Recall (prompt GPT_Majority): 0.7890466531440162\n",
      "F1 Score (prompt GPT_Majority): 0.7787787787787788\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 28  96]\n",
      " [ 46 407]]\n",
      "True Positives (TP): 407\n",
      "True Negatives (TN): 28\n",
      "False Positives (FP): 96\n",
      "False Negatives (FN): 46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gpt_name in gpt_names:\n",
    "    df_pred = metrics_dataframe(sentences_list, extract_metaphors(df_labels, name=gpt_name))\n",
    "    calculate_metrics(df_labels, gpt_name, Fuzzy=False)\n",
    "    get_confusion_matrix(df_true, df_pred, model_name=gpt_name)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaphor matching using Fuzzy distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpt_name in gpt_names:\n",
    "    df_labels = add_comparison_column_Fuzzy(df_labels, threshold=0.45, name=gpt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Metaphors (prompt GPT_1):  497\n",
      "Total number of True values for (prompt GPT_1):  451\n",
      "Ratio of Metaphors correctly identified (vs labeled data) (prompt GPT_1):  0.9074446680080482\n",
      "Ratio of Categories correctly identified (vs labeled data) (prompt GPT_1):  0.8048289738430584\n",
      "\n",
      "Total number of Metaphors (prompt GPT_2):  497\n",
      "Total number of True values for (prompt GPT_2):  453\n",
      "Ratio of Metaphors correctly identified (vs labeled data) (prompt GPT_2):  0.9114688128772636\n",
      "Ratio of Categories correctly identified (vs labeled data) (prompt GPT_2):  0.7806841046277666\n",
      "\n",
      "Total number of Metaphors (prompt GPT_3):  505\n",
      "Total number of True values for (prompt GPT_3):  460\n",
      "Ratio of Metaphors correctly identified (vs labeled data) (prompt GPT_3):  0.9108910891089109\n",
      "Ratio of Categories correctly identified (vs labeled data) (prompt GPT_3):  0.7782178217821782\n",
      "\n",
      "Total number of Metaphors (prompt GPT_Majority):  506\n",
      "Total number of True values for (prompt GPT_Majority):  461\n",
      "Ratio of Metaphors correctly identified (vs labeled data) (prompt GPT_Majority):  0.9110671936758893\n",
      "Ratio of Categories correctly identified (vs labeled data) (prompt GPT_Majority):  0.8003952569169961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gpt_name in gpt_names:\n",
    "        print(f\"Total number of Metaphors (prompt {gpt_name}): \", df_labels[f'Sentence_{gpt_name}'].apply(len).sum())\n",
    "        print(f\"Total number of True values for (prompt {gpt_name}): \", df_labels[f'Matched_Metaphors_Fuzzy_{gpt_name}'].apply(sum).sum())\n",
    "        print(f\"Ratio of Metaphors correctly identified (vs labeled data) (prompt {gpt_name}): \", df_labels[f'Matched_Metaphors_Fuzzy_{gpt_name}'].apply(sum).sum() / df_labels[f'Matched_Metaphors_Fuzzy_{gpt_name}'].apply(len).sum())\n",
    "        print(f\"Ratio of Categories correctly identified (vs labeled data) (prompt {gpt_name}): \", df_labels[f'Matched_Categories_Fuzzy_{gpt_name}'].apply(sum).sum() / df_labels[f'Matched_Categories_Fuzzy_{gpt_name}'].apply(len).sum())\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (prompt GPT_1): 0.9074446680080482\n",
      "Precision (prompt GPT_1): 0.9074446680080482\n",
      "Recall (prompt GPT_1): 0.9148073022312373\n",
      "F1 Score (prompt GPT_1): 0.9111111111111112\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 31  93]\n",
      " [ 52 401]]\n",
      "True Positives (TP): 401\n",
      "True Negatives (TN): 31\n",
      "False Positives (FP): 93\n",
      "False Negatives (FN): 52\n",
      "\n",
      "Accuracy (prompt GPT_2): 0.9114688128772636\n",
      "Precision (prompt GPT_2): 0.9114688128772636\n",
      "Recall (prompt GPT_2): 0.9188640973630832\n",
      "F1 Score (prompt GPT_2): 0.915151515151515\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 34  90]\n",
      " [ 49 404]]\n",
      "True Positives (TP): 404\n",
      "True Negatives (TN): 34\n",
      "False Positives (FP): 90\n",
      "False Negatives (FN): 49\n",
      "\n",
      "Accuracy (prompt GPT_3): 0.9108910891089109\n",
      "Precision (prompt GPT_3): 0.9108910891089109\n",
      "Recall (prompt GPT_3): 0.9330628803245437\n",
      "F1 Score (prompt GPT_3): 0.9218436873747495\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 26  98]\n",
      " [ 49 404]]\n",
      "True Positives (TP): 404\n",
      "True Negatives (TN): 26\n",
      "False Positives (FP): 98\n",
      "False Negatives (FN): 49\n",
      "\n",
      "Accuracy (prompt GPT_Majority): 0.9110671936758893\n",
      "Precision (prompt GPT_Majority): 0.9110671936758893\n",
      "Recall (prompt GPT_Majority): 0.9350912778904665\n",
      "F1 Score (prompt GPT_Majority): 0.922922922922923\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 28  96]\n",
      " [ 46 407]]\n",
      "True Positives (TP): 407\n",
      "True Negatives (TN): 28\n",
      "False Positives (FP): 96\n",
      "False Negatives (FN): 46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gpt_name in gpt_names:\n",
    "    df_pred = metrics_dataframe(sentences_list, extract_metaphors(df_labels, name=gpt_name))\n",
    "    calculate_metrics(df_labels, gpt_name, Fuzzy=True)\n",
    "    get_confusion_matrix(df_true, df_pred, model_name=gpt_name)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = extract_category(df_labels, name=\"Labeled\")\n",
    "metaphors_list = extract_metaphors(df_labels)\n",
    "\n",
    "\n",
    "# Get the true Y values (sentences matching with metaphors labeled)\n",
    "df_true = metrics_dataframe(category_list, metaphors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (prompt GPT_1): 0.7706237424547284\n",
      "Precision (prompt GPT_1): 0.7706237424547284\n",
      "Recall (prompt GPT_1): 0.7768762677484787\n",
      "F1 Score (prompt GPT_1): 0.7737373737373737\n",
      "\n",
      "\n",
      "Accuracy (prompt GPT_2): 0.7826961770623743\n",
      "Precision (prompt GPT_2): 0.7826961770623743\n",
      "Recall (prompt GPT_2): 0.7890466531440162\n",
      "F1 Score (prompt GPT_2): 0.7858585858585859\n",
      "\n",
      "\n",
      "Accuracy (prompt GPT_3): 0.7643564356435644\n",
      "Precision (prompt GPT_3): 0.7643564356435644\n",
      "Recall (prompt GPT_3): 0.7829614604462475\n",
      "F1 Score (prompt GPT_3): 0.7735470941883769\n",
      "\n",
      "\n",
      "Accuracy (prompt GPT_Majority): 0.7687747035573123\n",
      "Precision (prompt GPT_Majority): 0.7687747035573123\n",
      "Recall (prompt GPT_Majority): 0.7890466531440162\n",
      "F1 Score (prompt GPT_Majority): 0.7787787787787788\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gpt_name in gpt_names:\n",
    "    df_pred = metrics_dataframe(category_list, extract_category(df_labels, name=gpt_name))\n",
    "    calculate_metrics(df_labels, gpt_name, Fuzzy=False)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat GPT Labels for entire dataset EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of GPT-4 output for the first prompt:  406\n",
      "Lenght of GPT-4 output for the second prompt:  406\n",
      "Lenght of GPT-4 output for the third prompt:  406\n"
     ]
    }
   ],
   "source": [
    "# Load the GPT-4 output from the pickle file\n",
    "with open('GPT_Output/gpt_answer_all_1.pkl', 'rb') as f:\n",
    "    gpt_answer_all_1 = pickle.load(f)\n",
    "\n",
    "with open('GPT_Output/gpt_answer_all_2.pkl', 'rb') as f:\n",
    "    gpt_answer_all_2 = pickle.load(f)\n",
    "\n",
    "with open('GPT_Output/gpt_answer_all_3.pkl', 'rb') as f:\n",
    "    gpt_answer_all_3 = pickle.load(f)\n",
    "\n",
    "print(\"Lenght of GPT-4 output for the first prompt: \", len(gpt_answer_all_1))\n",
    "print(\"Lenght of GPT-4 output for the second prompt: \", len(gpt_answer_all_2))\n",
    "print(\"Lenght of GPT-4 output for the third prompt: \", len(gpt_answer_all_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset before adding GPT-4 output:  (519, 30)\n",
      "Shape of the dataset after adding GPT-4 output:  (519, 36)\n"
     ]
    }
   ],
   "source": [
    "# Drop the first element which is the initial prompt\n",
    "gpt_answer_all_1 = gpt_answer_all_1[1:]\n",
    "gpt_answer_all_2 = gpt_answer_all_2[1:]\n",
    "gpt_answer_all_3 = gpt_answer_all_3[1:]\n",
    "\n",
    "print(\"Shape of the dataset before adding GPT-4 output: \", df.shape)\n",
    "\n",
    "for gpt_name, gpt_answer in zip(gpt_names, [gpt_answer_all_1, gpt_answer_all_2, gpt_answer_all_3]):\n",
    "    df = add_columns_to_dataframe(df, gpt_answer, name=gpt_name)\n",
    "\n",
    "print(\"Shape of the dataset after adding GPT-4 output: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Sentences (with words_to_match):  3437\n",
      "\n",
      "Total number of sentences in the 'Sentence_GPT_1' column:  3060\n",
      "Total number of sentences in the 'Sentence_GPT_2' column:  3073\n",
      "Total number of sentences in the 'Sentence_GPT_3' column:  2999\n",
      "\n",
      "Ratio of GPT (Prompt 1) Metaphors to Sentences:  0.8903113180098924\n",
      "Ratio of GPT (Prompt 2) Metaphors to Sentences:  0.8940936863543788\n",
      "Ratio of GPT (Prompt 3) Metaphors to Sentences:  0.8725632819319173\n"
     ]
    }
   ],
   "source": [
    "# Sanity check:\n",
    "print(\"Total number of Sentences (with words_to_match): \", df['Sentences'].apply(len).sum())\n",
    "print(\"\")\n",
    "print(\"Total number of sentences in the 'Sentence_GPT_1' column: \", df['Sentence_GPT_1'].apply(len).sum())\n",
    "print(\"Total number of sentences in the 'Sentence_GPT_2' column: \", df['Sentence_GPT_2'].apply(len).sum())\n",
    "print(\"Total number of sentences in the 'Sentence_GPT_3' column: \", df['Sentence_GPT_3'].apply(len).sum())\n",
    "print(\"\")\n",
    "print(\"Ratio of GPT (Prompt 1) Metaphors to Sentences: \", df['Sentence_GPT_1'].apply(len).sum() / df['Sentences'].apply(len).sum())\n",
    "print(\"Ratio of GPT (Prompt 2) Metaphors to Sentences: \", df['Sentence_GPT_2'].apply(len).sum() / df['Sentences'].apply(len).sum())\n",
    "print(\"Ratio of GPT (Prompt 3) Metaphors to Sentences: \", df['Sentence_GPT_3'].apply(len).sum() / df['Sentences'].apply(len).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Voting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences in the 'Sentence_GPT_Majority' column:  3038\n",
      "Ratio of GPT (Majority Vote) Metaphors to Sentences:  0.8839103869653768\n"
     ]
    }
   ],
   "source": [
    "df = majority_voting_with_category(df)\n",
    "print(\"Total number of sentences in the 'Sentence_GPT_Majority' column: \", df['Sentence_GPT_Majority'].apply(len).sum())\n",
    "print(\"Ratio of GPT (Majority Vote) Metaphors to Sentences: \", df['Sentence_GPT_Majority'].apply(len).sum() / df['Sentences'].apply(len).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_comparison_column_GPT(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Metaphors:  3038\n",
      "Total number of True values:  2962\n",
      "Total number of False values:  76\n",
      "Ratio of Metaphors correctly matched with the 'original set of' Sentences:  0.9749835418038183\n"
     ]
    }
   ],
   "source": [
    "# Flatten the lists in the \"Matched_Metaphors\" column\n",
    "flattened_results = [item for sublist in df['Matched_Metaphors'] for item in sublist]\n",
    "\n",
    "# Count the True and False values\n",
    "true_count = flattened_results.count(True)\n",
    "false_count = flattened_results.count(False)\n",
    "\n",
    "print(\"Total number of Metaphors: \", df['Sentence_GPT_Majority'].apply(len).sum())\n",
    "print(\"Total number of True values: \", true_count)\n",
    "print(\"Total number of False values: \", false_count)\n",
    "print(\"Ratio of Metaphors correctly matched with the 'original set of' Sentences: \", true_count / len(flattened_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 3437 sentences containing the word 'inflation', 3038 were labeled as metaphors by Chat GPT 4o. \n",
    "\n",
    "However, 76 of them could not be matched to the original sentences again, which might be because Chat GPT returned a different sentence (not the exact same one). Or due to preprocessing issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnecessary columns: Sentence_GPT_1, Sentence_GPT_2, Sentence_GPT_3, Category_GPT_1, Category_GPT_2, Category_GPT_3 if they exist\n",
    "if 'Sentence_GPT_1' in df.columns:\n",
    "    df.drop(['Sentence_GPT_1', 'Sentence_GPT_2', 'Sentence_GPT_3', 'Category_GPT_1', 'Category_GPT_2', 'Category_GPT_3'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Save the final dataset to a CSV file\n",
    "df.to_csv('Data/Final_Data.csv', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: \n",
    "\n",
    "Create second dataset with all the senteces, their Metaphor classification and if metaphor also their category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Sentences list:  3437\n",
      "Length of Metaphors list:  3038\n",
      "Length of Category list:  3038\n",
      "Length of the new dataframe:  3437\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Matched</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We will in the future take the decisions that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a risk which in turn would affect infl...</td>\n",
       "      <td>True</td>\n",
       "      <td>disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our decision by stabilising inflationary expec...</td>\n",
       "      <td>True</td>\n",
       "      <td>plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We are not confronted with deflation but with ...</td>\n",
       "      <td>True</td>\n",
       "      <td>warfare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If longterm interest rates remain at a low lev...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Matched Category\n",
       "0  We will in the future take the decisions that ...     True  machine\n",
       "1  This is a risk which in turn would affect infl...     True  disease\n",
       "2  Our decision by stabilising inflationary expec...     True    plant\n",
       "3  We are not confronted with deflation but with ...     True  warfare\n",
       "4  If longterm interest rates remain at a low lev...    False     None"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_list = extract_sentences_column(df)\n",
    "metaphors_list = extract_metaphors(df, \"GPT_Majority\")\n",
    "category_list = extract_category(df, \"GPT_Majority\")\n",
    "\n",
    "print(\"Length of Sentences list: \", len(sentences_list))\n",
    "print(\"Length of Metaphors list: \", len(metaphors_list))\n",
    "print(\"Length of Category list: \", len(category_list))\n",
    "\n",
    "df_new = metrics_dataframe(sentences_list, metaphors_list, category_list) \n",
    "\n",
    "print(\"Length of the new dataframe: \", len(df_new))\n",
    "\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of Metaphors to Sentences:  0.8658713994762874\n"
     ]
    }
   ],
   "source": [
    "# Ratio of Metaphors to Sentences\n",
    "print(\"Ratio of Metaphors to Sentences: \", df_new['Matched'].sum() / len(df_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "orientation    1310\n",
       "other           770\n",
       "disease         267\n",
       "machine         237\n",
       "warfare         204\n",
       "plant            67\n",
       "fire             39\n",
       "liquids          39\n",
       "sports           25\n",
       "animal           18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#Save the final dataset to a CSV file\n",
    "df_new.to_csv('Data/Prediction_Data.csv', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
